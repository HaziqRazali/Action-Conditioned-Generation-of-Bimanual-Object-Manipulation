
# architecture
architecture = "models.action2pose.rnn"

# log and weights will be stored at log_root/experiment_name and weight_root/experiment_name respectively
# experiment_name != result_name so I can store the results given various settings
log_root		= "~/Action-Conditioned-Generation-of-Bimanual-Object-Manipulation/logs/action2pose"
weight_root 	= "~/Action-Conditioned-Generation-of-Bimanual-Object-Manipulation/weights/action2pose"
experiment_name	= "kit_rgbd/segmentation/rnn"

# dataset will be loaded from data_root/data_folder
data_loader			= "dataloaders.action2pose.kit_rgbd"
data_root			= "~/datasets/kit_rgbd"
data_name			= ""
# in case i want to manually provide a path to the cached data
cached_data_path	= None

# dataset settings
main_actions 			= ["task_1_k_cooking", "task_2_k_cooking_with_bowls", "task_3_k_pouring", "task_4_k_wiping", "task_6_w_hard_drive", "task_7_w_free_hard_drive", "task_8_w_hammering", "task_9_w_sawing"]
main_actions_scale		= []
sample_ratio			= [1, 1, 1, 1, 1, 1, 1, 1]
fine_actions			= ["idle", "approach", "retreat", "lift", "place", "hold", "pour", "cut", "hammer", "saw", "stir", "screw", "drink", "wipe"]
inp_length				= 0
out_length				= 0
time_step_size  		= 10
xyz_scale				= 0.1
kin_scale				= 1
add_distractors			= 0
num_extra_distractors	= -1
object_padded_length 	= 11
pose_padded_length		= 100
train_samples			= [0, 1, 2, 3, 4, 5, 6]
val_samples				= [7, 8, 9]
sample_from				= "full_sequence"
sample_till				= "full_sequence"
add_noise				= 1 
sigma					= 1
noise_scale				= 2 
noise_add_type			= "all_objects"
noise_probability		= 0.5

# optimization
batch_size			= 32
seed			 	= 1337
lr					= 1e-3
tr_step				= 100
va_step				= 100
loss_names			= ["lhand_action_ids", "rhand_action_ids"]
loss_functions		= ["padded_cross_entropy", "padded_cross_entropy"]
loss_weights		= ["[1.0]*1000", "[1.0]*1000"]
task_names			= ["all"]
task_components		= [["lhand_action_ids", "rhand_action_ids"]]
freeze				= None
reset_loss			= None

# architecture details
hand_xyz_dims					= [13, 14, 15, 25, 26, 37, 38, 39, 49, 50]

# pose encoder
pose_encoder_units				= [30, 128] 
pose_encoder_activations		= ["none"]
pose_rnn_encoder_units			= [128, 256, 2, 128, 256]
pose_rnn_encoder_activations	= ["relu"]

# other architecture details
object_type						= "all_3d_objects"
context							= 1

# checkpointing
restore_from_checkpoint	= 0
epoch_names		= [-1]
layer_names		= [["pose_embedder", "pose_encoder", "pose_encoder_hi", "lclf", "rclf"]]
strict			= 1
remove			= ["prior","posterior","distribution"]

# json results will be stored in result_root/result_name
# experiment_name != result_name so I can store the results given various settings
result_root		= "~/Action-Conditioned-Generation-of-Bimanual-Object-Manipulation/results/action2pose" 
result_name		= "kit_rgbd/segmentation/rnn"